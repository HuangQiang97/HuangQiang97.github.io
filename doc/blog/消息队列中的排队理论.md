## 消息队列中的排队理论

[toc]

#### 1，单队列单消费者

* MQ中默认一个队列只对应一个消费者，假设单位时间内新来$\lambda$个消息，消费者单位时间可以处理$\mu$条消息，不能及时被消费的消息将缓存在队列中，上述系统可以建模为一个`M/M/1`系统[^1]。

* 队列中消息的到达和消费可以建模为生灭过程[^2]，假设有$k$条待处理消息的状态为$S_k$，处于该状态的概率为$P_k$。

    <img src=".\assets\image-20240514223614793.png" alt="image-20240514223614793" style="zoom:40%;" />

* $S_k$可能因为有新消息到达转移到$S_{k+1}$，或者现有消息被消费转移到$S_{k-1}$，他们的转移速率可以定义为$P_k\lambda, P_{k}\mu$，二者之和定义为流出状态$S_k$的速率。

* $S_k$也可以通过在$S_{k-1}$时有新消息到达，或者在状态$S_{k+1}$时现有消息被消费转移得到。他们转移的速率可以定义为$P_{k-1}\lambda, P_{k+1}\mu$，二者之和定义为流入状态$S_k$的速率。

* 如果队列在状态$S_k$达到平衡，则流入状态$S_k$的速率等于流出状态$S_k$的速率，
  
    对于$k=0$时有
    $$
    P_{0}\lambda=P_{1}\mu
    $$
    
    
    对于$k>0$有
    $$
    P_k\lambda+P_{k}\mu=P_{k-1}\lambda+ P_{k+1}\mu
    $$
    结合上述两式可以获得
    $$
    P_k=P_{k-1}\frac{\lambda}{\mu}, k>0
    $$
    队列全部状态的概率和为一$\sum_{k=0}^{\infty}P_k=1$，通过对$P_k$进行等比数列求和求解得到
    $$
    P_k=(1-\frac{\lambda}{\mu})(\frac{\lambda}{\mu})^k
    $$
    
* 系统消息总数均值为处于各个状态的概率和：$L=\sum_{k=0}^\infty kP_k=\sum_{k=0}^\infty k(1-\frac{\lambda}{\mu})(\frac{\lambda}{\mu})^k=\frac{\lambda}{\mu-\lambda}$

* 等待消息总数均值为系统消息总数均值减去正在处理的消息数：$L_q=L-\frac{\lambda}{\mu}=\frac{\lambda}{\mu-\lambda}-\frac{\lambda}{\mu}$

* 应用`Little Law`[^3]获得消息在系统的平均逗留时间： $W=\frac{L}{\lambda }=\frac{1}{\mu−\lambda}$

* 应用`Little Law`获得消息在队列中平均等待时间：$ 𝑊_q=\frac{L_𝑞}{\lambda}=\frac{\lambda}{\mu(\mu-\lambda)}$

#### 2，单队列多消费者

* MQ开启批量消费，一个队列对应`n`个消费者，多个消费者共享同一个队列，假设单位时间内新到达$\lambda$个消息，每个消费者单位时间最多可以处理$\mu$条消息，不能及时被消费的消息将缓存在队列中，上述系统可以建模为一个`M/M/n`系统[^4]。

    <img src=".\assets\image-20240514223653294.png" alt="image-20240514223653294" style="zoom:40%;" />

* $S_k$可能因为有新消息到达从而转移到$S_{k+1}$，或者现有消息被消费转移到状态$S_{k-1}$。

    如果队列消息数小于消费者数$k<n$，则他们转移的速率可以分别定义为$P_k\lambda, kP_{k}\mu$；如果队列消息数大于等于消费者数$k>=n$，则他们转移的速率可以定义为$P_k\lambda, nP_{k}\mu$，二者之和定义为流出状态$S_k$的速率。

* $S_k$可以通过在$S_{k-1}$时有新消息到达，或者在状态$S_{k+1}$时现有消息被消费转移得到。

    如果队列消息数小于消费者$k<n$，则他们转移的速率可以定义为$P_{k-1}\lambda, (k+1)P_{k+1}\mu$；如果队列消息数大于等于消费者数$k>=n$，则他们转移的速率可以定义为$P_{k-1}\lambda, nP_{k+1}\mu$，二者之和定义为流入状态$S_k$的速率。

* 如果队列在状态$S_k$时到达平衡，则流入状态$S_k$的速率等于流出状态$S_k$的速率，

    对于$k=0$有
    $$
    P_{0}\lambda=P_{1}\mu
    $$
    对于$k<n$有
    $$
    P_k\lambda+kP_{k}\mu=P_{k-1}\lambda+ (k+1)P_{k+1}\mu
    $$
    对于$k\geq n$有
    $$
    P_k\lambda+nP_{k}\mu=P_{k-1}\lambda+ nP_{k+1}\mu
    $$
    综合上式递推得到系统空闲概率$P_0$，以及系统包含$k$条消息的概率为
    $$
    \begin{array}{ll}
    P_0 = \left( \sum_{k=0}^{n-1} \frac{(\lambda / \mu)^k}{k!} + \frac{(\lambda / \mu)^n}{n! \cdot (1 - \rho)} \right)^{-1}\\
    P_k = \frac{(\lambda / \mu)^k}{k!}  P_0& k < n\\
    P_k = \frac{(\lambda / \mu)^k}{n^{k-n} \cdot n!}  P_0 &k \geq n
    \end{array}
    $$

* 在队列中等待处理的消息总数均值为：$L_q = \frac{(n \lambda/\mu)^n}{n! \left(1 - \frac{\lambda}{n\mu}\right)^2} P_0$

* 系统平均消息总数均值为处于等待状态的消息总数均值加上正在处理的消息总数均值：$L = L_q + n \lambda/\mu$

* 应用`Little Law`获得消息在系统的平均逗留时间均值： $W = \frac{L}{\lambda}$

* 应用`Little Law`获得消息在队列中平均等待均值时间：$W_q = \frac{L_q}{\lambda}$

#### 3，性能对比

* 现在假设有5个消费者`n=5`，每个消费者单位时间内可以处理一条消息$\mu=1$。对于单队列单消费者情形构建n个独立的队列，每个队列关联一个消费者；对于单队列多消费者情形，系统只有一个队列，n个消费者共享该队列。

* 对于n个单队列单消费者构成的系统，定义系统负载$\rho=\frac{n\lambda}{n\mu}=\frac{\lambda}{\mu}$；

    对于包含n个消费者的单队列多消费者系统，定义系统负载$\rho=\frac{\lambda}{n\mu}$。

    当二者系统负载相同时，将在单位时间内收到相同数量的新消息。下图展示了二者在相同系统负载时队列中等待处理的消息总数均值$L_q $、系统消息总数均值$L$、消息在系统逗留时间均值$W$，和消息在队列中等待时间均值$W_q$，随系统负载$\rho$的变化关系。

<img src=".\assets\mml.png" alt="L" style="zoom: 62%;" /><img src=".\assets\mmw.png" alt="W" style="zoom:62%;" />

* 可见当新消息到来速度小于系统消息消费能力$\rho <1$的时候，`M/M/n`系统能立即处理新到来消息，没有消息积压，也没有等待处理耗时。然而==单队列单消费者系统相较于单队列多消费者系统，消息积压较为严重，消息等待处理时间更长==，在系统负载增大时，劣势更加明显。

#### 4，性能优化

* MQ出于消息顺序性消费考虑、以及单个队列读写性能受限的原因，默认限制每个分区只能由一个消费者组中的一个消费者消费。
* `M/M/1`和`M/M/n`系统性能差距主要来源于：由于队列间独立，并且没有类似`Golang`中`GMP`的消息窃取机制（同样出于有序性要求），当一些队列面临高压力出现长队列，而其他队列可能暂时空闲，相应空闲队列对应的消费者空转，导致系统资源利用率低，消息不能及时处理。
* MQ的解决方式是使用再平衡机制，在消费者与队列之间动态地重新分配队列来实现负载平衡。再平衡机制将在周期性延迟、消费者发生变化，以及订阅topic变化后，被触发执行再平衡。

##### 4.1，RocketMQ 再平衡实现

* Rocket MQ中在`RebalanceService#run()`中定时(默认20s)触发再平衡流程。

    ```java
    // RebalanceService#run()
    public void run() {
        long realWaitInterval = waitInterval;
        while (!this.isStopped()) {
            // 定时休眠后触发再平衡
            this.waitForRunning(realWaitInterval);
            boolean balanced = this.mqClientFactory.doRebalance();
            }
        }
    }
    ```

    具体通过`RebalanceImpl`实施平衡：再平衡过程中，获取当前所有活跃的消费者列表和所有队列的列表，然后根据轮询或者一致性哈希分配等算法将topic下队列分配给所有活跃的消费者。

    ```java
    // RebalanceImpl#doRebalance()
    public boolean doRebalance(final boolean isOrder) {
    	// 获取当前所有活跃的消费者列表和所有队列的列表
        for (final Map.Entry<String, SubscriptionData> entry : subTable.entrySet()) {
            final String topic = entry.getKey();
            // 执行再平衡
            boolean result = this.rebalanceByTopic(topic, isOrder);
        }
    }
    ```

    ```java
    // RebalanceImpl#rebalanceByTopic
    private boolean rebalanceByTopic(final String topic, final boolean isOrder) {
        // 获取topic对应的队列和consumer信息
        Set<MessageQueue> mqSet = this.topicSubscribeInfoTable.get(topic);
        List<String> cidAll = this.mQClientFactory.findConsumerIdList(topic, consumerGroup);
    	// 选择再平衡策略
        AllocateMessageQueueStrategy strategy = this.allocateMessageQueueStrategy;
    	// 完成再平衡
        List<MessageQueue> allocateResult = null;
        allocateResult = strategy.allocate(
            this.consumerGroup,
            this.mQClientFactory.getClientId(),
            mqAll,
            cidAll);
        }
    }
    ```

* 再平衡策略决定队列和消费者间的对应关系，RocketMQ提供了下列分配策略

    * ` AllocateMessageQueueAveragely`：默认策略，先计算队列数除以消费者数的余数$N_q\%N_c=N_m$，然后将余数$N_m$个队列依次分配给$N_m$个消费者，最后把剩余的队列连续的分为$(N_q-N_m)/N_c$份，依次分配给全部消费者。

    * `AllocateMessageQueueAveragelyByCircle`：每个消费者依次分配一个队列，循环分配，直至分配完毕全部队列。

    * `AllocateMessageQueueConsistentHash`：通过一致性hash算法计算队列所属消费者。此策略可以尽量减少 因为队列或者消费者数量发生变化，导致消费者与队列关联关系变化，从而需要重新建立TCP连接的数量。同时再平衡阶段消费者将不能正常消费消息，更少的关系变化，可以更快的完成再平衡过程，减少MQ不可用时间。

##### 4.2，Kafka 再平衡实现

* 再平衡流程将在消费者组或者topic发生变化后，当前消费者组领导者加入消费组后进行

    ```java
    // ConsumerCoordinator#onJoinComplete
    protected void onJoinComplete(int generation, String memberId, String assignmentStrategy, ByteBuffer assignmentBuffer) {
        // 再平衡策略
        ConsumerPartitionAssignor assignor = this.lookupAssignor(assignmentStrategy);
        // 待分配分区
        SortedSet<TopicPartition> assignedPartitions = new TreeSet(COMPARATOR);
        assignedPartitions.addAll(assignment.partitions());
        // 执行分配
        firstException.compareAndSet((Object)null, this.invokeOnAssignment(assignor, assignment));
        this.subscriptions.assignFromSubscribed(assignedPartitions);
        firstException.compareAndSet((Object)null, 	this.invokePartitionsAssigned(addedPartitions));
        }
    }
    ```

* 再平衡策略：Kafka提供了和RocketMQ相似的分配策略
    * `RangeAssignor`与`RocketMQ`的`AllocateMessageQueueAveragely`策略一致。
    * `RoundRobinAssignor`与`RocketMQ`的`AllocateMessageQueueAveragelyByCircle`策略一致。
    * `StickyAssignor`：分配尽量均匀，尽量与上一次分配的相同，尽量减少分配关系的变动，从而减少需要重新建立消费者与分区之间TCP连接的数量，缩短再平衡过程耗时，降低MQ不可用时间。。
    * `CooperativeStickyAssignor`：两阶段再平衡策略，先尝试只移动最少量的分区完成再分配，如果分配后不满足平衡条件，再进行完整的再平衡。
    

#### 附录

队列长度与逗留时间计算绘制脚本

```python
from scipy.special import factorial
import numpy as np
import matplotlib.pyplot as plt


# MM1 队列模型
def mm1_queue(lambda_, mu):
    if lambda_ >= mu:
        return "系统不稳定"
    rho = lambda_ / mu
    # 等候+服务人数
    L = rho / (1 - rho)
    # 等候+服务时间
    W = 1 / (mu - lambda_)
    # 等候人数
    Lq = rho**2 / (1 - rho)
    # 等候时间
    Wq = rho / (mu - lambda_)
    return L, W, Lq, Wq

# MMn 队列模型
def mmn_queue(lambda_, mu, n):
    # 计算流量强度
    rho = lambda_ / (n * mu)
    if rho >= 1:
        return "系统不稳定，请确保 rho < 1"

    # 计算P0
    sum_p = sum((lambda_ / mu)**k / factorial(k) for k in range(n))
    p0 = (sum_p + (lambda_ / mu)**n / (factorial(n) * (1 - rho)))**(-1)
    # 计算队列中的平均客户数 Lq
    lq = (rho**n * rho / factorial(n)) * p0 / (1 - rho)**2
    # 计算平均等待时间在队列中 Wq
    wq = lq / lambda_
    # 计算系统中的总平均客户数 L
    l = lq + lambda_ / mu
    # 计算系统中的总平均等待时间 W
    w = wq + 1 / mu

    return l, w, lq, wq



def plot(x, y,  y_label):
    # 绘制图表
    plt.figure()
    # 绘制等待时间
    plt.plot(x, y[0], label="M/M/1", marker='o')
    plt.plot(x, y[1], label="M/M/n", marker='o')
    plt.title(y_label+" vs $\\rho$")
    plt.xlabel("$\\rho$")
    plt.ylabel(y_label)
    plt.legend()
    plt.grid(True)


# 利用率从0.1到0.9
rho_values = np.linspace(0.1, 0.9, 9)
mu = 1
# 服务台数量
n = 5        

# 客户到达率
lambda_ = rho_values*mu  
mm1_array = np.zeros((len(rho_values), 4))
mmn_array = np.zeros((len(rho_values), 4))

for i in range(len(rho_values)):
    lam = lambda_[i]
    mm1_array[i] = mm1_queue(lam, mu)
    mmn_array[i] = mmn_queue(n*lam, mu, n)

plt.figure()
# 绘制队列长度
plt.plot(rho_values, n*mm1_array[:, 0], label="n$\\times$M/M/1 L", marker='o', color='r')
plt.plot(rho_values, mmn_array[:, 0], label="M/M/n L", marker='o', color='g')
plt.plot(rho_values, n*mm1_array[:, 2],
         label="n$\\times$M/M/1 Lq", marker='*', color='r')
plt.plot(rho_values, mmn_array[:, 2], label="M/M/n Lq", marker='*', color='g')
plt.title("$L,Lq$"+" vs $\\rho$")
plt.xlabel("$\\rho$")
plt.ylabel("$L,Lq$")
plt.legend()
plt.grid(True)

plt.figure()
# 绘制等待时间
plt.plot(rho_values, n*mm1_array[:, 1], label="n$\\times$M/M/1 W", marker='o', color='r')
plt.plot(rho_values, mmn_array[:, 1], label="M/M/n W", marker='o', color='g')
plt.plot(rho_values, n*mm1_array[:, 3],
         label="n$\\times$M/M/1 Wq", marker='*', color='r')
plt.plot(rho_values, mmn_array[:, 3], label="M/M/n Wq", marker='*', color='g')
plt.title("$W,Wq$"+" vs $\\rho$")
plt.xlabel("$\\rho$")
plt.ylabel("$W,Wq$")
plt.legend()
plt.grid(True)

plt.show()

```

#### 参考

[^1]: [M/M/1 queue]( https://zh.wikipedia.org/wiki/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E9%93%BE) 
[^2]: [生灭过程]( https://en.wikipedia.org/wiki/Birth%E2%80%93death_process) 
[^3]: [Little Law]( https://en.wikipedia.org/wiki/Little%27s_law) 
[^4]: [M/M/n queue]( https://en.wikipedia.org/wiki/M/M/c_queue) 